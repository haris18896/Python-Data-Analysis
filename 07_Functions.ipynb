{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Zo0S9L5Skyh1"
      ],
      "authorship_tag": "ABX9TyMnGoeTkEBJCV027xutPDjw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haris18896/Python-Data-Analysis/blob/main/07_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n",
        "\n",
        "## What is a Function\n",
        "\n",
        "### Notes\n",
        "\n",
        "* A **function** is a block of code that only runs when it's called.\n",
        "* You can pass data (called **parameters**) into a function.\n",
        "* The function can return data as a result.\n",
        "\n",
        "## Importance\n",
        "\n",
        "Enable us to resuse the code and make it more modular, important for complex data analysis and plotting routines.\n",
        "\n",
        "\n",
        "## Types of Functions\n",
        "\n",
        "| Type of Function             | Example Function              | Section            |\n",
        "|------------------------------|-------------------------------|--------------------|\n",
        "| Built-In functions           | `max()`                       | 1. Getting Started |\n",
        "| User-defined functions       | `def my_function(): pass`     | 16. Functions      |\n",
        "| Lambda functions             | `lambda x: x + 1`             | 17. Lambda         |\n",
        "| Standard Library functions   | `math.sqrt()`                 | 18. Modules        |\n",
        "| Third-Party Library Functions| `numpy.array()`               | 19. Library        |\n",
        "\n",
        "Note: We won't be covering Generator, Asynchronous, or Recursive Functions as they are out of scope of Data Analytics.\n",
        "\n",
        "\n",
        "# [Builtin functions](https://docs.python.org/3/library/functions.html)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gBvf44e9fzPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzrAtyxif2o6",
        "outputId": "e7f5b940-930a-46c3-a8c9-45c4101edca9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on built-in function all in module builtins:\n",
            "\n",
            "all(iterable, /)\n",
            "    Return True if bool(x) is True for all values x in the iterable.\n",
            "    \n",
            "    If the iterable is empty, return True.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import types\n",
        "\n",
        "print([func for func in dir(__builtins__) if isinstance(getattr(__builtins__, func), types.BuiltinFunctionType)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG6e74mhhuzg",
        "outputId": "095ec5db-d0b7-48be-f03d-f5efb28d9c5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__build_class__', '__import__', 'abs', 'aiter', 'all', 'anext', 'any', 'ascii', 'bin', 'breakpoint', 'callable', 'chr', 'compile', 'delattr', 'dir', 'divmod', 'eval', 'exec', 'format', 'getattr', 'globals', 'hasattr', 'hash', 'hex', 'id', 'isinstance', 'issubclass', 'iter', 'len', 'locals', 'max', 'min', 'next', 'oct', 'open', 'ord', 'pow', 'print', 'repr', 'round', 'setattr', 'sorted', 'sum', 'vars']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_list = [10000, 120000, 130000, 50000, 197692]\n",
        "\n",
        "def calculate_salary(salary, rate=.1):\n",
        "  total_salary = salary * (1 + rate)\n",
        "\n",
        "  return total_salary\n",
        "\n",
        "total_salary_list = [calculate_salary(salary) for salary in salary_list]\n",
        "\n",
        "total_salary_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcXdrv4GgtRr",
        "outputId": "ca193336-fc9c-45a7-e7d5-b9bf8e904348"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11000.0, 132000.0, 143000.0, 55000.00000000001, 217461.2]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lambda\n",
        "\n",
        "* anonymus functions\n",
        "* lambda x: x + 1"
      ],
      "metadata": {
        "id": "Zo0S9L5Skyh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mul_two = lambda x: x*2\n",
        "mul_two(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LheXQFdDk5uc",
        "outputId": "b7fb51cc-7197-41c7-d432-3f8ab34fa757"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(lambda x: x*2)(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEJ9CZS0lAwp",
        "outputId": "9932cc26-6759-4797-e885-f9038a620db1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(lambda x, y : x * 2 + y*3)(3, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3UCocr3lEQk",
        "outputId": "08a5f438-6ffe-44c9-e099-e4fcff816a09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(lambda *args: sum(args))(1,2,3,4,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSuh8_YglK7d",
        "outputId": "2e3b07f8-0960-4e20-b9e7-3312ee016945"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(lambda **kwargs: sum(kwargs.values()))(a=1, b=2, c=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlcY4uRtlPv9",
        "outputId": "43a351f9-8c15-4ef2-d3b1-449acb26d775"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(lambda **kwargs: kwargs.values())(a=1, b=2, c=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rVTf1uplSQ7",
        "outputId": "90c46167-3ef2-4fbb-9791-7e0099cfdd4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(lambda salary, rate : salary * (1 + rate))(1000, 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcGZ2QGdld8p",
        "outputId": "11945fb9-0408-43bc-e563-9ed40c379d13"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1100.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_salary_list = [(lambda x: x * (1 + 0.1))(salary) for salary in salary_list]\n",
        "\n",
        "total_salary_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC9l82j6lmA4",
        "outputId": "2c60c46b-2dda-434e-a801-30c231ea8b12"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11000.0, 132000.0, 143000.0, 55000.00000000001, 217461.2]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_data = [\n",
        "    {\n",
        "        'job_title': \"Data Scientist\",\n",
        "        \"job_skills\": [\"Python\", \"Machine Learning\", \"Statistics\"],\n",
        "        \"remote\": True\n",
        "    },\n",
        "     {\n",
        "         'job_title': \"Data Scientist\",\n",
        "        \"job_skills\": [\"SQL\", \"Data Visualization\", \"Data Cleaning\"],\n",
        "        \"remote\": False\n",
        "    },\n",
        "    {\n",
        "        'job_title':\"Machine Learning Engineer\",\n",
        "        \"job_skills\": [\"Python\", \"Machine Learning\", \"Cloud Computing\"],\n",
        "        \"remote\": True\n",
        "    },\n",
        "     {\n",
        "        'job_title':\"Data Engineer\",\n",
        "        \"job_skills\": [\"Python\", \"SQL\", \"Data Warehousing\"],\n",
        "        \"remote\": False\n",
        "    },\n",
        "    {\n",
        "        'job_title' : \"Business Intelligence Analyst\",\n",
        "        \"job_skills\": [\"Excel\", \"Power BI\", \"Data Analysis\"],\n",
        "        \"remote\": True\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "help(filter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqNViHN2mSlP",
        "outputId": "d66ec567-1855-4435-eaf2-586320bad734"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class filter in module builtins:\n",
            "\n",
            "class filter(object)\n",
            " |  filter(function or None, iterable) --> filter object\n",
            " |  \n",
            " |  Return an iterator yielding those items of iterable for which function(item)\n",
            " |  is true. If function is None, return the items that are true.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __getattribute__(self, name, /)\n",
            " |      Return getattr(self, name).\n",
            " |  \n",
            " |  __iter__(self, /)\n",
            " |      Implement iter(self).\n",
            " |  \n",
            " |  __next__(self, /)\n",
            " |      Implement next(self).\n",
            " |  \n",
            " |  __reduce__(...)\n",
            " |      Return state information for pickling.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(*args, **kwargs) from builtins.type\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(filter(lambda job: job['remote'], job_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVdHzZYrnNPt",
        "outputId": "09d10200-3c35-4179-c29c-99b954b94250"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'job_title': 'Data Scientist',\n",
              "  'job_skills': ['Python', 'Machine Learning', 'Statistics'],\n",
              "  'remote': True},\n",
              " {'job_title': 'Machine Learning Engineer',\n",
              "  'job_skills': ['Python', 'Machine Learning', 'Cloud Computing'],\n",
              "  'remote': True},\n",
              " {'job_title': 'Business Intelligence Analyst',\n",
              "  'job_skills': ['Excel', 'Power BI', 'Data Analysis'],\n",
              "  'remote': True}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(filter(lambda job: job['remote'] and 'Python' in job[\"job_skills\"], job_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIJ-aE4lnag3",
        "outputId": "16654529-6218-4254-c181-94a524612989"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'job_title': 'Data Scientist',\n",
              "  'job_skills': ['Python', 'Machine Learning', 'Statistics'],\n",
              "  'remote': True},\n",
              " {'job_title': 'Machine Learning Engineer',\n",
              "  'job_skills': ['Python', 'Machine Learning', 'Cloud Computing'],\n",
              "  'remote': True}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module"
      ],
      "metadata": {
        "id": "ak6KmB7mntmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import my_module\n",
        "\n",
        "my_module.skill_list\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrCXXKt5n3V_",
        "outputId": "5ae2ce90-a715-44b4-c47a-0d2e5818ffa6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['python', 'sql', 'java']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_module.skill('python')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dMPge8cupexz",
        "outputId": "b9e28709-46de-4386-c498-876803a21979"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'python is my favourite skill'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from job_analyzer import calculate_salary, calculate_bonus\n",
        "\n",
        "calculate_salary(100)\n",
        "\n",
        "# calculate_bonus(1100, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSsDYZ33phYX",
        "outputId": "63d420f1-da72-4f48-986a-3e0d0c90b4cf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "110.00000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(calculate_salary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-i1X3Y-p3qQ",
        "outputId": "216adecb-81d9-4cad-c900-1b0302edd45d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function calculate_salary in module job_analyzer:\n",
            "\n",
            "calculate_salary(salary, rate=0.1)\n",
            "    Calculate the total salary based on the base salary and bonus\n",
            "    \n",
            "    Args:\n",
            "    salary (Float): base Salary.\n",
            "    rate (Float): The bonus rate. Default is .1\n",
            "    \n",
            "    Returns:\n",
            "    float: The total salary\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_list = [9800, 1000, 5670, 1234, 4321]\n",
        "\n",
        "import statistics\n",
        "\n",
        "statistics.mean(salary_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx5fvZVar7b-",
        "outputId": "b3118d71-23a5-4abf-dc05-01cfb3fe2430"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4405"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(statistics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvT25ptgsNjg",
        "outputId": "5a4d7dec-3e07-404c-f702-cff9a841d4ae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on module statistics:\n",
            "\n",
            "NAME\n",
            "    statistics - Basic statistics module.\n",
            "\n",
            "MODULE REFERENCE\n",
            "    https://docs.python.org/3.10/library/statistics.html\n",
            "    \n",
            "    The following documentation is automatically generated from the Python\n",
            "    source files.  It may be incomplete, incorrect or include features that\n",
            "    are considered implementation detail and may vary between Python\n",
            "    implementations.  When in doubt, consult the module reference at the\n",
            "    location listed above.\n",
            "\n",
            "DESCRIPTION\n",
            "    This module provides functions for calculating statistics of data, including\n",
            "    averages, variance, and standard deviation.\n",
            "    \n",
            "    Calculating averages\n",
            "    --------------------\n",
            "    \n",
            "    ==================  ==================================================\n",
            "    Function            Description\n",
            "    ==================  ==================================================\n",
            "    mean                Arithmetic mean (average) of data.\n",
            "    fmean               Fast, floating point arithmetic mean.\n",
            "    geometric_mean      Geometric mean of data.\n",
            "    harmonic_mean       Harmonic mean of data.\n",
            "    median              Median (middle value) of data.\n",
            "    median_low          Low median of data.\n",
            "    median_high         High median of data.\n",
            "    median_grouped      Median, or 50th percentile, of grouped data.\n",
            "    mode                Mode (most common value) of data.\n",
            "    multimode           List of modes (most common values of data).\n",
            "    quantiles           Divide data into intervals with equal probability.\n",
            "    ==================  ==================================================\n",
            "    \n",
            "    Calculate the arithmetic mean (\"the average\") of data:\n",
            "    \n",
            "    >>> mean([-1.0, 2.5, 3.25, 5.75])\n",
            "    2.625\n",
            "    \n",
            "    \n",
            "    Calculate the standard median of discrete data:\n",
            "    \n",
            "    >>> median([2, 3, 4, 5])\n",
            "    3.5\n",
            "    \n",
            "    \n",
            "    Calculate the median, or 50th percentile, of data grouped into class intervals\n",
            "    centred on the data values provided. E.g. if your data points are rounded to\n",
            "    the nearest whole number:\n",
            "    \n",
            "    >>> median_grouped([2, 2, 3, 3, 3, 4])  #doctest: +ELLIPSIS\n",
            "    2.8333333333...\n",
            "    \n",
            "    This should be interpreted in this way: you have two data points in the class\n",
            "    interval 1.5-2.5, three data points in the class interval 2.5-3.5, and one in\n",
            "    the class interval 3.5-4.5. The median of these data points is 2.8333...\n",
            "    \n",
            "    \n",
            "    Calculating variability or spread\n",
            "    ---------------------------------\n",
            "    \n",
            "    ==================  =============================================\n",
            "    Function            Description\n",
            "    ==================  =============================================\n",
            "    pvariance           Population variance of data.\n",
            "    variance            Sample variance of data.\n",
            "    pstdev              Population standard deviation of data.\n",
            "    stdev               Sample standard deviation of data.\n",
            "    ==================  =============================================\n",
            "    \n",
            "    Calculate the standard deviation of sample data:\n",
            "    \n",
            "    >>> stdev([2.5, 3.25, 5.5, 11.25, 11.75])  #doctest: +ELLIPSIS\n",
            "    4.38961843444...\n",
            "    \n",
            "    If you have previously calculated the mean, you can pass it as the optional\n",
            "    second argument to the four \"spread\" functions to avoid recalculating it:\n",
            "    \n",
            "    >>> data = [1, 2, 2, 4, 4, 4, 5, 6]\n",
            "    >>> mu = mean(data)\n",
            "    >>> pvariance(data, mu)\n",
            "    2.5\n",
            "    \n",
            "    \n",
            "    Statistics for relations between two inputs\n",
            "    -------------------------------------------\n",
            "    \n",
            "    ==================  ====================================================\n",
            "    Function            Description\n",
            "    ==================  ====================================================\n",
            "    covariance          Sample covariance for two variables.\n",
            "    correlation         Pearson's correlation coefficient for two variables.\n",
            "    linear_regression   Intercept and slope for simple linear regression.\n",
            "    ==================  ====================================================\n",
            "    \n",
            "    Calculate covariance, Pearson's correlation, and simple linear regression\n",
            "    for two inputs:\n",
            "    \n",
            "    >>> x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "    >>> y = [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
            "    >>> covariance(x, y)\n",
            "    0.75\n",
            "    >>> correlation(x, y)  #doctest: +ELLIPSIS\n",
            "    0.31622776601...\n",
            "    >>> linear_regression(x, y)  #doctest:\n",
            "    LinearRegression(slope=0.1, intercept=1.5)\n",
            "    \n",
            "    \n",
            "    Exceptions\n",
            "    ----------\n",
            "    \n",
            "    A single exception is defined: StatisticsError is a subclass of ValueError.\n",
            "\n",
            "CLASSES\n",
            "    builtins.ValueError(builtins.Exception)\n",
            "        StatisticsError\n",
            "    builtins.object\n",
            "        NormalDist\n",
            "    \n",
            "    class NormalDist(builtins.object)\n",
            "     |  NormalDist(mu=0.0, sigma=1.0)\n",
            "     |  \n",
            "     |  Normal distribution of a random variable\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __add__(x1, x2)\n",
            "     |      Add a constant or another NormalDist instance.\n",
            "     |      \n",
            "     |      If *other* is a constant, translate mu by the constant,\n",
            "     |      leaving sigma unchanged.\n",
            "     |      \n",
            "     |      If *other* is a NormalDist, add both the means and the variances.\n",
            "     |      Mathematically, this works only if the two distributions are\n",
            "     |      independent or if they are jointly normally distributed.\n",
            "     |  \n",
            "     |  __eq__(x1, x2)\n",
            "     |      Two NormalDist objects are equal if their mu and sigma are both equal.\n",
            "     |  \n",
            "     |  __getstate__(self)\n",
            "     |  \n",
            "     |  __hash__(self)\n",
            "     |      NormalDist objects hash equal if their mu and sigma are both equal.\n",
            "     |  \n",
            "     |  __init__(self, mu=0.0, sigma=1.0)\n",
            "     |      NormalDist where mu is the mean and sigma is the standard deviation.\n",
            "     |  \n",
            "     |  __mul__(x1, x2)\n",
            "     |      Multiply both mu and sigma by a constant.\n",
            "     |      \n",
            "     |      Used for rescaling, perhaps to change measurement units.\n",
            "     |      Sigma is scaled with the absolute value of the constant.\n",
            "     |  \n",
            "     |  __neg__(x1)\n",
            "     |      Negates mu while keeping sigma the same.\n",
            "     |  \n",
            "     |  __pos__(x1)\n",
            "     |      Return a copy of the instance.\n",
            "     |  \n",
            "     |  __radd__ = __add__(x1, x2)\n",
            "     |  \n",
            "     |  __repr__(self)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __rmul__ = __mul__(x1, x2)\n",
            "     |  \n",
            "     |  __rsub__(x1, x2)\n",
            "     |      Subtract a NormalDist from a constant or another NormalDist.\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  __sub__(x1, x2)\n",
            "     |      Subtract a constant or another NormalDist instance.\n",
            "     |      \n",
            "     |      If *other* is a constant, translate by the constant mu,\n",
            "     |      leaving sigma unchanged.\n",
            "     |      \n",
            "     |      If *other* is a NormalDist, subtract the means and add the variances.\n",
            "     |      Mathematically, this works only if the two distributions are\n",
            "     |      independent or if they are jointly normally distributed.\n",
            "     |  \n",
            "     |  __truediv__(x1, x2)\n",
            "     |      Divide both mu and sigma by a constant.\n",
            "     |      \n",
            "     |      Used for rescaling, perhaps to change measurement units.\n",
            "     |      Sigma is scaled with the absolute value of the constant.\n",
            "     |  \n",
            "     |  cdf(self, x)\n",
            "     |      Cumulative distribution function.  P(X <= x)\n",
            "     |  \n",
            "     |  inv_cdf(self, p)\n",
            "     |      Inverse cumulative distribution function.  x : P(X <= x) = p\n",
            "     |      \n",
            "     |      Finds the value of the random variable such that the probability of\n",
            "     |      the variable being less than or equal to that value equals the given\n",
            "     |      probability.\n",
            "     |      \n",
            "     |      This function is also called the percent point function or quantile\n",
            "     |      function.\n",
            "     |  \n",
            "     |  overlap(self, other)\n",
            "     |      Compute the overlapping coefficient (OVL) between two normal distributions.\n",
            "     |      \n",
            "     |      Measures the agreement between two normal probability distributions.\n",
            "     |      Returns a value between 0.0 and 1.0 giving the overlapping area in\n",
            "     |      the two underlying probability density functions.\n",
            "     |      \n",
            "     |          >>> N1 = NormalDist(2.4, 1.6)\n",
            "     |          >>> N2 = NormalDist(3.2, 2.0)\n",
            "     |          >>> N1.overlap(N2)\n",
            "     |          0.8035050657330205\n",
            "     |  \n",
            "     |  pdf(self, x)\n",
            "     |      Probability density function.  P(x <= X < x+dx) / dx\n",
            "     |  \n",
            "     |  quantiles(self, n=4)\n",
            "     |      Divide into *n* continuous intervals with equal probability.\n",
            "     |      \n",
            "     |      Returns a list of (n - 1) cut points separating the intervals.\n",
            "     |      \n",
            "     |      Set *n* to 4 for quartiles (the default).  Set *n* to 10 for deciles.\n",
            "     |      Set *n* to 100 for percentiles which gives the 99 cuts points that\n",
            "     |      separate the normal distribution in to 100 equal sized groups.\n",
            "     |  \n",
            "     |  samples(self, n, *, seed=None)\n",
            "     |      Generate *n* samples for a given mean and standard deviation.\n",
            "     |  \n",
            "     |  zscore(self, x)\n",
            "     |      Compute the Standard Score.  (x - mean) / stdev\n",
            "     |      \n",
            "     |      Describes *x* in terms of the number of standard deviations\n",
            "     |      above or below the mean of the normal distribution.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Class methods defined here:\n",
            "     |  \n",
            "     |  from_samples(data) from builtins.type\n",
            "     |      Make a normal distribution instance from sample data.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Readonly properties defined here:\n",
            "     |  \n",
            "     |  mean\n",
            "     |      Arithmetic mean of the normal distribution.\n",
            "     |  \n",
            "     |  median\n",
            "     |      Return the median of the normal distribution\n",
            "     |  \n",
            "     |  mode\n",
            "     |      Return the mode of the normal distribution\n",
            "     |      \n",
            "     |      The mode is the value x where which the probability density\n",
            "     |      function (pdf) takes its maximum value.\n",
            "     |  \n",
            "     |  stdev\n",
            "     |      Standard deviation of the normal distribution.\n",
            "     |  \n",
            "     |  variance\n",
            "     |      Square of the standard deviation.\n",
            "    \n",
            "    class StatisticsError(builtins.ValueError)\n",
            "     |  Method resolution order:\n",
            "     |      StatisticsError\n",
            "     |      builtins.ValueError\n",
            "     |      builtins.Exception\n",
            "     |      builtins.BaseException\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object (if defined)\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from builtins.ValueError:\n",
            "     |  \n",
            "     |  __init__(self, /, *args, **kwargs)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from builtins.ValueError:\n",
            "     |  \n",
            "     |  __new__(*args, **kwargs) from builtins.type\n",
            "     |      Create and return a new object.  See help(type) for accurate signature.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from builtins.BaseException:\n",
            "     |  \n",
            "     |  __delattr__(self, name, /)\n",
            "     |      Implement delattr(self, name).\n",
            "     |  \n",
            "     |  __getattribute__(self, name, /)\n",
            "     |      Return getattr(self, name).\n",
            "     |  \n",
            "     |  __reduce__(...)\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self, /)\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setattr__(self, name, value, /)\n",
            "     |      Implement setattr(self, name, value).\n",
            "     |  \n",
            "     |  __setstate__(...)\n",
            "     |  \n",
            "     |  __str__(self, /)\n",
            "     |      Return str(self).\n",
            "     |  \n",
            "     |  with_traceback(...)\n",
            "     |      Exception.with_traceback(tb) --\n",
            "     |      set self.__traceback__ to tb and return self.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from builtins.BaseException:\n",
            "     |  \n",
            "     |  __cause__\n",
            "     |      exception cause\n",
            "     |  \n",
            "     |  __context__\n",
            "     |      exception context\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |  \n",
            "     |  __suppress_context__\n",
            "     |  \n",
            "     |  __traceback__\n",
            "     |  \n",
            "     |  args\n",
            "\n",
            "FUNCTIONS\n",
            "    correlation(x, y, /)\n",
            "        Pearson's correlation coefficient\n",
            "        \n",
            "        Return the Pearson's correlation coefficient for two inputs. Pearson's\n",
            "        correlation coefficient *r* takes values between -1 and +1. It measures the\n",
            "        strength and direction of the linear relationship, where +1 means very\n",
            "        strong, positive linear relationship, -1 very strong, negative linear\n",
            "        relationship, and 0 no linear relationship.\n",
            "        \n",
            "        >>> x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "        >>> y = [9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
            "        >>> correlation(x, x)\n",
            "        1.0\n",
            "        >>> correlation(x, y)\n",
            "        -1.0\n",
            "    \n",
            "    covariance(x, y, /)\n",
            "        Covariance\n",
            "        \n",
            "        Return the sample covariance of two inputs *x* and *y*. Covariance\n",
            "        is a measure of the joint variability of two inputs.\n",
            "        \n",
            "        >>> x = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "        >>> y = [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
            "        >>> covariance(x, y)\n",
            "        0.75\n",
            "        >>> z = [9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
            "        >>> covariance(x, z)\n",
            "        -7.5\n",
            "        >>> covariance(z, x)\n",
            "        -7.5\n",
            "    \n",
            "    fmean(data)\n",
            "        Convert data to floats and compute the arithmetic mean.\n",
            "        \n",
            "        This runs faster than the mean() function and it always returns a float.\n",
            "        If the input dataset is empty, it raises a StatisticsError.\n",
            "        \n",
            "        >>> fmean([3.5, 4.0, 5.25])\n",
            "        4.25\n",
            "    \n",
            "    geometric_mean(data)\n",
            "        Convert data to floats and compute the geometric mean.\n",
            "        \n",
            "        Raises a StatisticsError if the input dataset is empty,\n",
            "        if it contains a zero, or if it contains a negative value.\n",
            "        \n",
            "        No special efforts are made to achieve exact results.\n",
            "        (However, this may change in the future.)\n",
            "        \n",
            "        >>> round(geometric_mean([54, 24, 36]), 9)\n",
            "        36.0\n",
            "    \n",
            "    harmonic_mean(data, weights=None)\n",
            "        Return the harmonic mean of data.\n",
            "        \n",
            "        The harmonic mean is the reciprocal of the arithmetic mean of the\n",
            "        reciprocals of the data.  It can be used for averaging ratios or\n",
            "        rates, for example speeds.\n",
            "        \n",
            "        Suppose a car travels 40 km/hr for 5 km and then speeds-up to\n",
            "        60 km/hr for another 5 km. What is the average speed?\n",
            "        \n",
            "            >>> harmonic_mean([40, 60])\n",
            "            48.0\n",
            "        \n",
            "        Suppose a car travels 40 km/hr for 5 km, and when traffic clears,\n",
            "        speeds-up to 60 km/hr for the remaining 30 km of the journey. What\n",
            "        is the average speed?\n",
            "        \n",
            "            >>> harmonic_mean([40, 60], weights=[5, 30])\n",
            "            56.0\n",
            "        \n",
            "        If ``data`` is empty, or any element is less than zero,\n",
            "        ``harmonic_mean`` will raise ``StatisticsError``.\n",
            "    \n",
            "    linear_regression(x, y, /)\n",
            "        Slope and intercept for simple linear regression.\n",
            "        \n",
            "        Return the slope and intercept of simple linear regression\n",
            "        parameters estimated using ordinary least squares. Simple linear\n",
            "        regression describes relationship between an independent variable\n",
            "        *x* and a dependent variable *y* in terms of linear function:\n",
            "        \n",
            "            y = slope * x + intercept + noise\n",
            "        \n",
            "        where *slope* and *intercept* are the regression parameters that are\n",
            "        estimated, and noise represents the variability of the data that was\n",
            "        not explained by the linear regression (it is equal to the\n",
            "        difference between predicted and actual values of the dependent\n",
            "        variable).\n",
            "        \n",
            "        The parameters are returned as a named tuple.\n",
            "        \n",
            "        >>> x = [1, 2, 3, 4, 5]\n",
            "        >>> noise = NormalDist().samples(5, seed=42)\n",
            "        >>> y = [3 * x[i] + 2 + noise[i] for i in range(5)]\n",
            "        >>> linear_regression(x, y)  #doctest: +ELLIPSIS\n",
            "        LinearRegression(slope=3.09078914170..., intercept=1.75684970486...)\n",
            "    \n",
            "    mean(data)\n",
            "        Return the sample arithmetic mean of data.\n",
            "        \n",
            "        >>> mean([1, 2, 3, 4, 4])\n",
            "        2.8\n",
            "        \n",
            "        >>> from fractions import Fraction as F\n",
            "        >>> mean([F(3, 7), F(1, 21), F(5, 3), F(1, 3)])\n",
            "        Fraction(13, 21)\n",
            "        \n",
            "        >>> from decimal import Decimal as D\n",
            "        >>> mean([D(\"0.5\"), D(\"0.75\"), D(\"0.625\"), D(\"0.375\")])\n",
            "        Decimal('0.5625')\n",
            "        \n",
            "        If ``data`` is empty, StatisticsError will be raised.\n",
            "    \n",
            "    median(data)\n",
            "        Return the median (middle value) of numeric data.\n",
            "        \n",
            "        When the number of data points is odd, return the middle data point.\n",
            "        When the number of data points is even, the median is interpolated by\n",
            "        taking the average of the two middle values:\n",
            "        \n",
            "        >>> median([1, 3, 5])\n",
            "        3\n",
            "        >>> median([1, 3, 5, 7])\n",
            "        4.0\n",
            "    \n",
            "    median_grouped(data, interval=1)\n",
            "        Return the 50th percentile (median) of grouped continuous data.\n",
            "        \n",
            "        >>> median_grouped([1, 2, 2, 3, 4, 4, 4, 4, 4, 5])\n",
            "        3.7\n",
            "        >>> median_grouped([52, 52, 53, 54])\n",
            "        52.5\n",
            "        \n",
            "        This calculates the median as the 50th percentile, and should be\n",
            "        used when your data is continuous and grouped. In the above example,\n",
            "        the values 1, 2, 3, etc. actually represent the midpoint of classes\n",
            "        0.5-1.5, 1.5-2.5, 2.5-3.5, etc. The middle value falls somewhere in\n",
            "        class 3.5-4.5, and interpolation is used to estimate it.\n",
            "        \n",
            "        Optional argument ``interval`` represents the class interval, and\n",
            "        defaults to 1. Changing the class interval naturally will change the\n",
            "        interpolated 50th percentile value:\n",
            "        \n",
            "        >>> median_grouped([1, 3, 3, 5, 7], interval=1)\n",
            "        3.25\n",
            "        >>> median_grouped([1, 3, 3, 5, 7], interval=2)\n",
            "        3.5\n",
            "        \n",
            "        This function does not check whether the data points are at least\n",
            "        ``interval`` apart.\n",
            "    \n",
            "    median_high(data)\n",
            "        Return the high median of data.\n",
            "        \n",
            "        When the number of data points is odd, the middle value is returned.\n",
            "        When it is even, the larger of the two middle values is returned.\n",
            "        \n",
            "        >>> median_high([1, 3, 5])\n",
            "        3\n",
            "        >>> median_high([1, 3, 5, 7])\n",
            "        5\n",
            "    \n",
            "    median_low(data)\n",
            "        Return the low median of numeric data.\n",
            "        \n",
            "        When the number of data points is odd, the middle value is returned.\n",
            "        When it is even, the smaller of the two middle values is returned.\n",
            "        \n",
            "        >>> median_low([1, 3, 5])\n",
            "        3\n",
            "        >>> median_low([1, 3, 5, 7])\n",
            "        3\n",
            "    \n",
            "    mode(data)\n",
            "        Return the most common data point from discrete or nominal data.\n",
            "        \n",
            "        ``mode`` assumes discrete data, and returns a single value. This is the\n",
            "        standard treatment of the mode as commonly taught in schools:\n",
            "        \n",
            "            >>> mode([1, 1, 2, 3, 3, 3, 3, 4])\n",
            "            3\n",
            "        \n",
            "        This also works with nominal (non-numeric) data:\n",
            "        \n",
            "            >>> mode([\"red\", \"blue\", \"blue\", \"red\", \"green\", \"red\", \"red\"])\n",
            "            'red'\n",
            "        \n",
            "        If there are multiple modes with same frequency, return the first one\n",
            "        encountered:\n",
            "        \n",
            "            >>> mode(['red', 'red', 'green', 'blue', 'blue'])\n",
            "            'red'\n",
            "        \n",
            "        If *data* is empty, ``mode``, raises StatisticsError.\n",
            "    \n",
            "    multimode(data)\n",
            "        Return a list of the most frequently occurring values.\n",
            "        \n",
            "        Will return more than one result if there are multiple modes\n",
            "        or an empty list if *data* is empty.\n",
            "        \n",
            "        >>> multimode('aabbbbbbbbcc')\n",
            "        ['b']\n",
            "        >>> multimode('aabbbbccddddeeffffgg')\n",
            "        ['b', 'd', 'f']\n",
            "        >>> multimode('')\n",
            "        []\n",
            "    \n",
            "    pstdev(data, mu=None)\n",
            "        Return the square root of the population variance.\n",
            "        \n",
            "        See ``pvariance`` for arguments and other details.\n",
            "        \n",
            "        >>> pstdev([1.5, 2.5, 2.5, 2.75, 3.25, 4.75])\n",
            "        0.986893273527251\n",
            "    \n",
            "    pvariance(data, mu=None)\n",
            "        Return the population variance of ``data``.\n",
            "        \n",
            "        data should be a sequence or iterable of Real-valued numbers, with at least one\n",
            "        value. The optional argument mu, if given, should be the mean of\n",
            "        the data. If it is missing or None, the mean is automatically calculated.\n",
            "        \n",
            "        Use this function to calculate the variance from the entire population.\n",
            "        To estimate the variance from a sample, the ``variance`` function is\n",
            "        usually a better choice.\n",
            "        \n",
            "        Examples:\n",
            "        \n",
            "        >>> data = [0.0, 0.25, 0.25, 1.25, 1.5, 1.75, 2.75, 3.25]\n",
            "        >>> pvariance(data)\n",
            "        1.25\n",
            "        \n",
            "        If you have already calculated the mean of the data, you can pass it as\n",
            "        the optional second argument to avoid recalculating it:\n",
            "        \n",
            "        >>> mu = mean(data)\n",
            "        >>> pvariance(data, mu)\n",
            "        1.25\n",
            "        \n",
            "        Decimals and Fractions are supported:\n",
            "        \n",
            "        >>> from decimal import Decimal as D\n",
            "        >>> pvariance([D(\"27.5\"), D(\"30.25\"), D(\"30.25\"), D(\"34.5\"), D(\"41.75\")])\n",
            "        Decimal('24.815')\n",
            "        \n",
            "        >>> from fractions import Fraction as F\n",
            "        >>> pvariance([F(1, 4), F(5, 4), F(1, 2)])\n",
            "        Fraction(13, 72)\n",
            "    \n",
            "    quantiles(data, *, n=4, method='exclusive')\n",
            "        Divide *data* into *n* continuous intervals with equal probability.\n",
            "        \n",
            "        Returns a list of (n - 1) cut points separating the intervals.\n",
            "        \n",
            "        Set *n* to 4 for quartiles (the default).  Set *n* to 10 for deciles.\n",
            "        Set *n* to 100 for percentiles which gives the 99 cuts points that\n",
            "        separate *data* in to 100 equal sized groups.\n",
            "        \n",
            "        The *data* can be any iterable containing sample.\n",
            "        The cut points are linearly interpolated between data points.\n",
            "        \n",
            "        If *method* is set to *inclusive*, *data* is treated as population\n",
            "        data.  The minimum value is treated as the 0th percentile and the\n",
            "        maximum value is treated as the 100th percentile.\n",
            "    \n",
            "    stdev(data, xbar=None)\n",
            "        Return the square root of the sample variance.\n",
            "        \n",
            "        See ``variance`` for arguments and other details.\n",
            "        \n",
            "        >>> stdev([1.5, 2.5, 2.5, 2.75, 3.25, 4.75])\n",
            "        1.0810874155219827\n",
            "    \n",
            "    variance(data, xbar=None)\n",
            "        Return the sample variance of data.\n",
            "        \n",
            "        data should be an iterable of Real-valued numbers, with at least two\n",
            "        values. The optional argument xbar, if given, should be the mean of\n",
            "        the data. If it is missing or None, the mean is automatically calculated.\n",
            "        \n",
            "        Use this function when your data is a sample from a population. To\n",
            "        calculate the variance from the entire population, see ``pvariance``.\n",
            "        \n",
            "        Examples:\n",
            "        \n",
            "        >>> data = [2.75, 1.75, 1.25, 0.25, 0.5, 1.25, 3.5]\n",
            "        >>> variance(data)\n",
            "        1.3720238095238095\n",
            "        \n",
            "        If you have already calculated the mean of your data, you can pass it as\n",
            "        the optional second argument ``xbar`` to avoid recalculating it:\n",
            "        \n",
            "        >>> m = mean(data)\n",
            "        >>> variance(data, m)\n",
            "        1.3720238095238095\n",
            "        \n",
            "        This function does not check that ``xbar`` is actually the mean of\n",
            "        ``data``. Giving arbitrary values for ``xbar`` may lead to invalid or\n",
            "        impossible results.\n",
            "        \n",
            "        Decimals and Fractions are supported:\n",
            "        \n",
            "        >>> from decimal import Decimal as D\n",
            "        >>> variance([D(\"27.5\"), D(\"30.25\"), D(\"30.25\"), D(\"34.5\"), D(\"41.75\")])\n",
            "        Decimal('31.01875')\n",
            "        \n",
            "        >>> from fractions import Fraction as F\n",
            "        >>> variance([F(1, 6), F(1, 2), F(5, 3)])\n",
            "        Fraction(67, 108)\n",
            "\n",
            "DATA\n",
            "    __all__ = ['NormalDist', 'StatisticsError', 'correlation', 'covariance...\n",
            "\n",
            "FILE\n",
            "    /usr/lib/python3.10/statistics.py\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean, median, mode\n",
        "\n",
        "mean(salary_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BJ82vhesPiS",
        "outputId": "b4fcabcb-52ff-4109-8d36-c5721b7ab13a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4405"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "median(salary_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbZQDXYqsU74",
        "outputId": "a614eccc-333f-46ee-a656-a7783340dcb0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4321"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode(salary_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfgyjlFQsWXl",
        "outputId": "e3980f87-6bca-4e48-896b-3817788ad695"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9800"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_science_jobs = [\n",
        "    {'job_title': 'Data Scientist', 'job_skills': \"['Python', 'SQL', 'Machine Learning']\", 'job_date': '2023-05-12'},\n",
        "    {'job_title': 'Machine Learning Engineer', 'job_skills': \"['Python', 'TensorFlow', 'Deep Learning']\", 'job_date': '2023-05-15'},\n",
        "    {'job_title': 'Data Analyst', 'job_skills': \"['SQL', 'R', 'Tableau']\", 'job_date': '2023-05-10'},\n",
        "    {'job_title': 'Business Intelligence Developer', 'job_skills': \"['SQL', 'PowerBI', 'Data Warehousing']\", 'job_date': '2023-05-08'},\n",
        "    {'job_title': 'Data Engineer', 'job_skills': \"['Python', 'Spark', 'Hadoop']\", 'job_date': '2023-05-18'},\n",
        "    {'job_title': 'AI Specialist', 'job_skills': \"['Python', 'PyTorch', 'AI Ethics']\", 'job_date': '2023-05-20'}\n",
        "]"
      ],
      "metadata": {
        "id": "hMLr9_IgsYeI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, date\n",
        "\n",
        "datetime.now()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ax2p6Nvsokx",
        "outputId": "feb60266-ea01-4885-8e89-d4cda83261b2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(2024, 6, 9, 11, 16, 57, 21021)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data_science_jobs[0][\"job_date\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIjIgFFms99l",
        "outputId": "7d16a027-b5e5-483b-8b3c-2233c89581e3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(datetime.strptime(data_science_jobs[0][\"job_date\"], \"%Y-%m-%d\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYf-rhb9tWkF",
        "outputId": "b13b52c7-fdb2-4e0c-d488-bfa51803ec75"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-12 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for job in data_science_jobs:\n",
        "  job[\"job_date\"] = datetime.strptime(job[\"job_date\"], \"%Y-%m-%d\")"
      ],
      "metadata": {
        "id": "lA0Ce6JXtq1h"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_science_jobs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joramQjqt3qq",
        "outputId": "8bee3783-36ab-4903-9465-2a83ce61bd10"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'job_title': 'Data Scientist',\n",
              "  'job_skills': \"['Python', 'SQL', 'Machine Learning']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 12, 0, 0)},\n",
              " {'job_title': 'Machine Learning Engineer',\n",
              "  'job_skills': \"['Python', 'TensorFlow', 'Deep Learning']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 15, 0, 0)},\n",
              " {'job_title': 'Data Analyst',\n",
              "  'job_skills': \"['SQL', 'R', 'Tableau']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 10, 0, 0)},\n",
              " {'job_title': 'Business Intelligence Developer',\n",
              "  'job_skills': \"['SQL', 'PowerBI', 'Data Warehousing']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 8, 0, 0)},\n",
              " {'job_title': 'Data Engineer',\n",
              "  'job_skills': \"['Python', 'Spark', 'Hadoop']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 18, 0, 0)},\n",
              " {'job_title': 'AI Specialist',\n",
              "  'job_skills': \"['Python', 'PyTorch', 'AI Ethics']\",\n",
              "  'job_date': datetime.datetime(2023, 5, 20, 0, 0)}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abstract Syntax Tree"
      ],
      "metadata": {
        "id": "-673SsseuDgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "for job in data_science_jobs:\n",
        "  job['job_skills'] = ast.literal_eval(job[\"job_skills\"])\n",
        "\n",
        "data_science_jobs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3wq7Mtdt9Mb",
        "outputId": "c8d730b2-abb7-45b8-ea89-e658700c376f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'job_title': 'Data Scientist',\n",
              "  'job_skills': ['Python', 'SQL', 'Machine Learning'],\n",
              "  'job_date': datetime.datetime(2023, 5, 12, 0, 0)},\n",
              " {'job_title': 'Machine Learning Engineer',\n",
              "  'job_skills': ['Python', 'TensorFlow', 'Deep Learning'],\n",
              "  'job_date': datetime.datetime(2023, 5, 15, 0, 0)},\n",
              " {'job_title': 'Data Analyst',\n",
              "  'job_skills': ['SQL', 'R', 'Tableau'],\n",
              "  'job_date': datetime.datetime(2023, 5, 10, 0, 0)},\n",
              " {'job_title': 'Business Intelligence Developer',\n",
              "  'job_skills': ['SQL', 'PowerBI', 'Data Warehousing'],\n",
              "  'job_date': datetime.datetime(2023, 5, 8, 0, 0)},\n",
              " {'job_title': 'Data Engineer',\n",
              "  'job_skills': ['Python', 'Spark', 'Hadoop'],\n",
              "  'job_date': datetime.datetime(2023, 5, 18, 0, 0)},\n",
              " {'job_title': 'AI Specialist',\n",
              "  'job_skills': ['Python', 'PyTorch', 'AI Ethics'],\n",
              "  'job_date': datetime.datetime(2023, 5, 20, 0, 0)}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library"
      ],
      "metadata": {
        "id": "-fKop1Q1uw3H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L_95W0PxuYlj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}